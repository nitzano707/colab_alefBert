# -*- coding: utf-8 -*-
"""
alephbert_utils.py

×¤×•×ª×— ×¢"×™ ×“"×¨ × ×™×¦×Ÿ ××œ×™×§×™×
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import ipywidgets as widgets
from IPython.display import display, clear_output
from sentence_transformers import SentenceTransformer, util
import bidi.algorithm
from arabic_reshaper import reshape

warnings.filterwarnings('ignore')

# ×¤×•× ×§×¦×™×” ×œ×ª×™×§×•×Ÿ ×¢×‘×¨×™×ª (×‘×©×‘×™×œ ×’×¨×¤×™× ×‘×œ×‘×“)
def fix_hebrew_text(text):
    try:
        reshaped_text = reshape(text)
        bidi_text = bidi.algorithm.get_display(reshaped_text)
        return bidi_text
    except:
        return text

# ×¢×™×¦×•×‘ ×’×¨×¤×™×
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
plt.rcParams['font.family'] = 'DejaVu Sans'

# ×ž×—×œ×§×ª × ×™×ª×•×—
class SeedSentenceAnalyzer:
    def __init__(self, seed_sentence, model="imvladikon/sentence-transformers-alephbert"):
        self.seed_sentence = seed_sentence.strip()
        self.model_name = model
        self.model = SentenceTransformer(model)
        self.sentences = []
        self.similarities = []
        self.df = None
        print(f"×¤×•×ª×— ×¢"×™ ×“``×¨ × ×™×¦×Ÿ ××œ×™×§×™×")
        print(f"--------------------")
        print(f"ðŸŒ± ×ž×©×¤×˜ ×”×–×¨×¢: \"{self.seed_sentence}\"")
        print(f"ðŸ¤– ×ž×•×“×œ: {self.model_name}")

    def load_sentences_from_csv(self, csv_path, sentence_column='sentence'):
        try:
            self.df = pd.read_csv(csv_path, encoding='utf-8')
            print(f"ðŸ“‚ ×§×•×‘×¥ CSV × ×˜×¢×Ÿ ×¢× {len(self.df)} ×©×•×¨×•×ª")

            if sentence_column not in self.df.columns:
                print(f"âŒ ×¢×ž×•×“×” '{sentence_column}' ×œ× × ×ž×¦××”")
                print(f"ðŸ“‹ ×¢×ž×•×“×•×ª ×–×ž×™× ×•×ª: {list(self.df.columns)}")
                return None

            self.df = self.df.dropna(subset=[sentence_column])
            self.df = self.df[self.df[sentence_column].str.strip() != '']
            self.df = self.df[self.df[sentence_column].str.strip() != self.seed_sentence]
            self.df = self.df.reset_index(drop=True)

            self.sentences = self.df[sentence_column].tolist()
            print(f"âœ… × ×˜×¢× ×• {len(self.sentences)} ×ž×©×¤×˜×™× ×ª×§×™× ×™×")

            print(f"ðŸ“ ×“×•×’×ž×” ×ž×ž×©×¤×˜×™× ×©× ×˜×¢× ×•:\n")
            for i, sentence in enumerate(self.sentences[:5], 1):
                print(f"{i:2d}. {sentence}")
            if len(self.sentences) > 5:
                print(f"... ×•×¢×•×“ {len(self.sentences) - 5} ×ž×©×¤×˜×™×")

            return self.df
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×§×•×‘×¥: {e}")
            return None

    def calculate_similarities_to_seed(self):
        if not self.sentences:
            print("âŒ ××™×Ÿ ×ž×©×¤×˜×™× ×œ×¢×™×‘×•×“. ×˜×¢×Ÿ ×§×•×‘×¥ CSV ×§×•×“×.")
            return None

        print(f"ðŸ”„ ×ž×—×©×‘ ×“×ž×™×•×Ÿ ×¢×‘×•×¨ {len(self.sentences)} ×ž×©×¤×˜×™× ×œ×ž×©×¤×˜ ×”×–×¨×¢...")
        print("â³ ×–×” ×”×¨×‘×” ×™×•×ª×¨ ×ž×”×™×¨ ×ž××©×¨ ×—×™×©×•×‘ ×ž×˜×¨×™×¦×” ×ž×œ××”!")

        try:
            seed_emb = self.model.encode(self.seed_sentence, convert_to_tensor=True)
            sent_embs = self.model.encode(self.sentences, convert_to_tensor=True)
            self.similarities = util.cos_sim(seed_emb, sent_embs).cpu().numpy().flatten().tolist()

            print(f"âœ… ×”×¡×ª×™×™×! ×—×•×©×‘×• {len(self.similarities)} ×”×©×•×•××•×ª")

            if self.df is not None:
                self.df['similarity_score'] = self.similarities
                self.df = self.df.sort_values('similarity_score', ascending=False).reset_index(drop=True)

            return self.similarities
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×—×™×©×•×‘ ×“×ž×™×•×Ÿ: {e}")
            return None

    def display_results(self, num_strong=5, num_medium=5):
        if not self.similarities:
            print("âŒ ×¢×“×™×™×Ÿ ×œ× ×—×•×©×‘×• ×¦×™×•× ×™×")
            return None

        all_matches = [(i, sentence, score) for i, (sentence, score) in enumerate(zip(self.sentences, self.similarities))]
        all_matches.sort(key=lambda x: x[2], reverse=True)

        strong = [m for m in all_matches if m[2] >= 0.75]
        medium = [m for m in all_matches if 0.70 <= m[2] < 0.75]
        weak = [m for m in all_matches if m[2] < 0.70]

        print(f"\nðŸŒ± ×ž×©×¤×˜ ×”×–×¨×¢: \"{self.seed_sentence}\"")
        print("=" * 100)

        # ×—×–×§
        if strong:
            show_n = min(num_strong, len(strong))
            print(f"\nðŸŸ¢ ×“×ž×™×•×Ÿ ×—×–×§ (â‰¥0.75) ({len(strong)} ×ž×©×¤×˜×™×):")
            print("ðŸ“‹ ×ž×¦×™×’", show_n, "×ž×ª×•×š", len(strong))
            print("-" * 100)
            for rank, (i, s, sc) in enumerate(strong[:show_n], 1):
                print(f"ðŸŸ¢ #{rank:2d} | ×¦×™×•×Ÿ: {sc:.4f} ({sc*100:.1f}%) | ×©×•×¨×” {i+1:3d}")
                print(f"    ðŸ“ \"{s}\"")
                print()

        # ×‘×™× ×•× ×™
        if medium:
            show_n = min(num_medium, len(medium))
            print(f"\nðŸŸ¡ ×“×ž×™×•×Ÿ ×‘×™× ×•× ×™ (0.70-0.749) ({len(medium)} ×ž×©×¤×˜×™×):")
            print("ðŸ“‹ ×ž×¦×™×’", show_n, "×ž×ª×•×š", len(medium))
            print("-" * 100)
            for rank, (i, s, sc) in enumerate(medium[:show_n], 1):
                print(f"ðŸŸ¡ #{rank:2d} | ×¦×™×•×Ÿ: {sc:.4f} ({sc*100:.1f}%) | ×©×•×¨×” {i+1:3d}")
                print(f"    ðŸ“ \"{s}\"")
                print()

        print(f"\nðŸ“Š ×¡×™×›×•×:")
        print(f"ðŸ”¥ ×—×–×§ (â‰¥0.75): {len(strong):3d} ×ž×©×¤×˜×™×")
        print(f"ðŸŸ¡ ×‘×™× ×•× ×™ (0.70-0.749): {len(medium):3d} ×ž×©×¤×˜×™×")
        print(f"ðŸ”µ ×—×œ×© (<0.70): {len(weak):3d} ×ž×©×¤×˜×™×")
        print(f"ðŸ“ ×¡×”\"×›: {len(all_matches):3d} ×ž×©×¤×˜×™×")
        if all_matches:
            best_score = all_matches[0][2]
            print(f"ðŸŽ¯ ×”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨: {best_score:.4f} ({best_score*100:.1f}%)")

    def create_visualizations(self):
        scores = np.array(self.similarities)
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))

        categories = [fix_hebrew_text('×“×ž×™×•×Ÿ ×—×–×§ (â‰¥0.75)'),
                      fix_hebrew_text('×“×ž×™×•×Ÿ ×‘×™× ×•× ×™ (0.70-0.749)'),
                      fix_hebrew_text('×“×ž×™×•×Ÿ ×—×œ×© (<0.70)')]
        counts = [len([s for s in scores if s >= 0.75]),
                  len([s for s in scores if 0.70 <= s < 0.75]),
                  len([s for s in scores if s < 0.70])]
        axes[0,0].bar(categories, counts, color=['green','gold','skyblue'])
        axes[0,0].set_title(fix_hebrew_text("×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×¨×ž×•×ª ×“×ž×™×•×Ÿ"))

        axes[0,1].hist(scores, bins=20, alpha=0.7, color='lightblue', edgecolor='black')
        axes[0,1].axvline(np.mean(scores), color='red', linestyle='--', label=fix_hebrew_text(f'×ž×ž×•×¦×¢: {np.mean(scores):.3f}'))
        axes[0,1].axvline(np.median(scores), color='green', linestyle='--', label=fix_hebrew_text(f'×—×¦×™×•×Ÿ: {np.median(scores):.3f}'))
        axes[0,1].legend()
        axes[0,1].set_title(fix_hebrew_text("×”×ª×¤×œ×’×•×ª ×¦×™×•× ×™ ×“×ž×™×•×Ÿ"))

        top_15_idx = np.argsort(scores)[-15:][::-1]
        top_15_scores = scores[top_15_idx]
        axes[0,2].bar(range(1,16), top_15_scores, color='green')
        axes[0,2].axhline(y=0.75, color='darkgreen', linestyle='--', label=fix_hebrew_text('×—×–×§ (0.75)'))
        axes[0,2].axhline(y=0.70, color='orange', linestyle='--', label=fix_hebrew_text('×‘×™× ×•× ×™ (0.70)'))
        axes[0,2].legend()
        axes[0,2].set_title(fix_hebrew_text("×˜×•×¤ 15 ×¦×™×•× ×™ ×“×ž×™×•×Ÿ"))

        axes[1,0].boxplot(scores, patch_artist=True, boxprops=dict(facecolor='lightgreen', alpha=0.7))
        axes[1,0].axhline(y=0.75, color='darkgreen', linestyle='--')
        axes[1,0].axhline(y=0.70, color='orange', linestyle='--')
        axes[1,0].set_title(fix_hebrew_text("Box Plot"))

        top_20_idx = np.argsort(scores)[-20:][::-1]
        heatmap_data = scores[top_20_idx].reshape(4, 5)
        im = axes[1,1].imshow(heatmap_data, cmap='RdYlGn', vmin=0, vmax=1)
        for i in range(4):
            for j in range(5):
                axes[1,1].text(j, i, f"{heatmap_data[i,j]:.3f}", ha="center", va="center", color="black")
        axes[1,1].set_title(fix_hebrew_text("×ž×¤×ª ×—×•× - ×˜×•×¤ 20"))
        fig.colorbar(im, ax=axes[1,1])

        axes[1,2].axis('off')
        plt.tight_layout(pad=3.0)
        plt.show()

# ×˜×•×¤×¡ ××™× ×˜×¨××§×˜×™×‘×™ (ipywidgets)
def create_analysis_form():
    print("""
ðŸ“ ×”×•×¨××•×ª ×œ×”×›× ×ª ×§×•×‘×¥ CSV:
1. ×¦×•×¨ ×§×•×‘×¥ ×¢× ×¢×ž×•×“×” ×‘×©× 'sentence'
2. ×›×œ ×©×•×¨×” ×ž×›×™×œ×” ×ž×©×¤×˜ ××—×“
3. ×©×ž×•×¨ ××ª ×”×§×•×‘×¥ ×‘-UTF-8
""")

    seed_text = widgets.Textarea(
        value='',
        placeholder='×”×›× ×¡ ×›××Ÿ ××ª ×ž×©×¤×˜ ×”×–×¨×¢...',
        description='×ž×©×¤×˜ ×”×–×¨×¢:',
        layout=widgets.Layout(width='80%')
    )

    file_upload = widgets.FileUpload(
        accept='.csv',
        multiple=False,
        description='×¦×™×¨×•×£ ×§×•×‘×¥'
    )

    column_name = widgets.Text(
        value='sentence',
        description='×¢×ž×•×“×ª ×˜×§×¡×˜:',
        layout=widgets.Layout(width='50%')
    )

    num_strong = widgets.IntSlider(
        value=5, min=0, max=50, step=1,
        description='×ž×©×¤×˜×™× ×—×–×§×™× (â‰¥0.75):',
        style={'description_width': 'initial'},
        layout=widgets.Layout(width='80%')
    )

    num_medium = widgets.IntSlider(
        value=5, min=0, max=50, step=1,
        description='×ž×©×¤×˜×™× ×‘×™× ×•× ×™×™× (0.70-0.749):',
        style={'description_width': 'initial'},
        layout=widgets.Layout(width='80%')
    )

    analyze_button = widgets.Button(
        description='ðŸ” ×”×¨×¦×ª × ×™×ª×•×—',
        button_style='success',
        layout=widgets.Layout(width='200px', height='40px')
    )

    def on_analyze_clicked(b):
        if not seed_text.value.strip():
            print("âŒ ×™×© ×œ×”×–×™×Ÿ ×ž×©×¤×˜ ×–×¨×¢")
            return
        if not file_upload.value:
            print("âŒ ×™×© ×œ×”×¢×œ×•×ª ×§×•×‘×¥ CSV")
            return

        uploaded_file = list(file_upload.value.values())[0]
        filename = 'uploaded_file.csv'
        with open(filename, 'wb') as f:
            f.write(uploaded_file['content'])

        print("ðŸš€ ×ž×ª×—×™×œ × ×™×ª×•×—...")
        analyzer = SeedSentenceAnalyzer(seed_text.value.strip())
        df = analyzer.load_sentences_from_csv(filename, column_name.value)
        if df is None:
            return
        similarities = analyzer.calculate_similarities_to_seed()
        if similarities is None:
            return
        analyzer.display_results(num_strong.value, num_medium.value)
        analyzer.create_visualizations()
        print("\nðŸŽ‰ ×”× ×™×ª×•×— ×”×•×©×œ× ×‘×”×¦×œ×—×”!")

    analyze_button.on_click(on_analyze_clicked)

    form = widgets.VBox([
        seed_text, file_upload, column_name, num_strong, num_medium, analyze_button
    ])
    display(form)
